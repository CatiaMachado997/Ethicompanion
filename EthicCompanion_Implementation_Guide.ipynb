{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22dbe2a",
   "metadata": {},
   "source": [
    "# EthicCompanion MVP Implementation Guide\n",
    "## Using GitHub Copilot Agent for Rapid Development\n",
    "\n",
    "This comprehensive guide will help you implement the EthicCompanion MVP efficiently using GitHub Copilot Agent throughout the development process. We'll leverage Copilot's capabilities to accelerate backend development, frontend creation, AI integration, and documentation.\n",
    "\n",
    "### üéØ **Current Status**\n",
    "‚úÖ **Project Structure Created**  \n",
    "‚úÖ **Backend Dependencies Installed** (FastAPI, LangChain, Gemini, Claude, ChromaDB, etc.)  \n",
    "‚úÖ **FastAPI Server Running** at `http://localhost:8000`  \n",
    "‚úÖ **English Knowledge Base** translated and ready  \n",
    "\n",
    "### üöÄ **Next Implementation Steps**\n",
    "1. Advanced Backend Endpoints with Copilot Agent\n",
    "2. LLM Integration (Gemini, Claude, Gemma 3n)\n",
    "3. RAG Pipeline with Vector Search\n",
    "4. Ethical Guardrails Implementation\n",
    "5. Flutter Frontend Development\n",
    "6. Full System Integration & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dce1cb",
   "metadata": {},
   "source": [
    "## 1. üìÅ Project Structure Setup with Copilot Agent\n",
    "\n",
    "Since we've already completed the initial setup, let's focus on optimizing our existing structure and adding missing components using Copilot Agent.\n",
    "\n",
    "### ‚úÖ Already Completed:\n",
    "- ‚úÖ Folder structure: `ethiccompanion-mvp/backend/`, `frontend/`, `ethical_knowledge_base/`\n",
    "- ‚úÖ FastAPI project with `main.py` and `requirements.txt`\n",
    "- ‚úÖ Flutter app with `pubspec.yaml` and `main.dart`\n",
    "- ‚úÖ `.gitignore` for Python/FastAPI and Flutter\n",
    "- ‚úÖ Requirements installed: FastAPI, LangChain, Gemini, Claude, ChromaDB\n",
    "\n",
    "### üîß Next Copilot Agent Actions:\n",
    "\n",
    "#### **Configuration Files Enhancement**\n",
    "\n",
    "**Copilot Prompt for `.env.example`:**\n",
    "```\n",
    "Create a .env.example file for a FastAPI project that includes placeholders for:\n",
    "- GEMINI_API_KEY\n",
    "- CLAUDE_API_KEY  \n",
    "- GCP_PROJECT_ID\n",
    "- VERTEX_AI_LOCATION\n",
    "- CHROMADB_HOST\n",
    "- OPENAI_API_KEY (for moderation)\n",
    "Include comments explaining each variable's purpose.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the .env.example file using Copilot-suggested content\n",
    "import os\n",
    "\n",
    "env_example_content = \"\"\"\n",
    "# EthicCompanion Environment Variables\n",
    "# Copy this file to .env and fill in your actual API keys\n",
    "\n",
    "# Google AI APIs\n",
    "GEMINI_API_KEY=your_gemini_api_key_here\n",
    "GCP_PROJECT_ID=your_gcp_project_id\n",
    "VERTEX_AI_LOCATION=us-central1\n",
    "\n",
    "# Anthropic Claude API\n",
    "CLAUDE_API_KEY=your_claude_api_key_here\n",
    "\n",
    "# Vector Database\n",
    "CHROMADB_HOST=localhost\n",
    "CHROMADB_PORT=8000\n",
    "\n",
    "# Content Moderation (Optional)\n",
    "OPENAI_API_KEY=your_openai_api_key_for_moderation\n",
    "\n",
    "# Application Settings\n",
    "DEBUG=True\n",
    "LOG_LEVEL=INFO\n",
    "MAX_TOKENS=2048\n",
    "TEMPERATURE=0.7\n",
    "\"\"\"\n",
    "\n",
    "# Check if we're in the backend directory\n",
    "backend_path = \"/Users/catiamachado/Documents/Ethicompanion/Ethicompanion/ethiccompanion-mvp/backend\"\n",
    "env_example_path = os.path.join(backend_path, \".env.example\")\n",
    "\n",
    "with open(env_example_path, \"w\") as f:\n",
    "    f.write(env_example_content.strip())\n",
    "\n",
    "print(f\"‚úÖ Created .env.example at: {env_example_path}\")\n",
    "print(\"\\nüìù Next Copilot Action: Copy this to .env and fill in your API keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bcf370",
   "metadata": {},
   "source": [
    "## 2. üîß Backend Development - Enhanced FastAPI Endpoints\n",
    "\n",
    "Now we'll enhance our existing FastAPI backend with Copilot Agent to create robust ethical guidance endpoints.\n",
    "\n",
    "### üéØ **Copilot Prompts for Enhanced Endpoints**\n",
    "\n",
    "#### **Primary Ethical Guidance Endpoint**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "Create a FastAPI POST endpoint /ask_ethical that:\n",
    "1. Accepts user_query: str and optional image_data: str (base64 encoded)\n",
    "2. Returns structured ethical_advice with reasoning, sources, and confidence level\n",
    "3. Uses Pydantic models for request/response validation\n",
    "4. Includes proper error handling and logging\n",
    "5. Integrates with rate limiting for production use\n",
    "```\n",
    "\n",
    "#### **Additional Specialized Endpoints**\n",
    "\n",
    "**Copilot Prompts:**\n",
    "```\n",
    "\"Create a /analyze_news endpoint that accepts news_text and returns bias analysis and emotional impact assessment\"\n",
    "\n",
    "\"Generate a /peace_techniques endpoint that returns personalized mindfulness suggestions based on user stress_level and time_available\"\n",
    "\n",
    "\"Design a /constructive_actions endpoint that suggests specific ethical actions based on user_concern and user_location\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041064cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Pydantic Models (Generated with Copilot Agent)\n",
    "# Add this to app/models/chat_models.py\n",
    "\n",
    "enhanced_models_code = '''\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import Optional, List, Dict, Any\n",
    "from enum import Enum\n",
    "import base64\n",
    "\n",
    "class StressLevel(str, Enum):\n",
    "    LOW = \"low\"\n",
    "    MODERATE = \"moderate\"\n",
    "    HIGH = \"high\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n",
    "class EthicalRequest(BaseModel):\n",
    "    user_query: str = Field(..., min_length=1, max_length=2000, description=\"User's ethical question or concern\")\n",
    "    image_data: Optional[str] = Field(None, description=\"Base64 encoded image data\")\n",
    "    context: Optional[Dict[str, Any]] = Field(default_factory=dict, description=\"Additional context\")\n",
    "    user_stress_level: Optional[StressLevel] = Field(StressLevel.MODERATE, description=\"Current stress level\")\n",
    "    \n",
    "    @validator('image_data')\n",
    "    def validate_image_data(cls, v):\n",
    "        if v:\n",
    "            try:\n",
    "                base64.b64decode(v)\n",
    "            except Exception:\n",
    "                raise ValueError('Invalid base64 image data')\n",
    "        return v\n",
    "\n",
    "class EthicalSource(BaseModel):\n",
    "    title: str\n",
    "    content_snippet: str\n",
    "    relevance_score: float = Field(ge=0.0, le=1.0)\n",
    "\n",
    "class EthicalResponse(BaseModel):\n",
    "    ethical_advice: str = Field(..., description=\"Main ethical guidance\")\n",
    "    reasoning: str = Field(..., description=\"Explanation of the advice\")\n",
    "    sources: List[EthicalSource] = Field(default_factory=list)\n",
    "    confidence_level: float = Field(ge=0.0, le=1.0, description=\"AI confidence in the advice\")\n",
    "    suggested_actions: List[str] = Field(default_factory=list)\n",
    "    peace_techniques: List[str] = Field(default_factory=list)\n",
    "    \n",
    "class NewsAnalysisRequest(BaseModel):\n",
    "    news_text: str = Field(..., min_length=10, max_length=5000)\n",
    "    source_url: Optional[str] = None\n",
    "\n",
    "class NewsAnalysisResponse(BaseModel):\n",
    "    bias_score: float = Field(ge=0.0, le=1.0, description=\"Detected bias level\")\n",
    "    emotional_impact: str = Field(..., description=\"Emotional impact assessment\")\n",
    "    fact_check_suggestions: List[str] = Field(default_factory=list)\n",
    "    balanced_perspective: str = Field(..., description=\"More balanced viewpoint\")\n",
    "'''\n",
    "\n",
    "print(\"üìù Enhanced Pydantic Models for Copilot Integration:\")\n",
    "print(\"=\" * 60)\n",
    "print(enhanced_models_code)\n",
    "print(\"\\n‚úÖ Use Copilot to refine these models further!\")\n",
    "print(\"üí° Copilot Prompt: 'Enhance these Pydantic models with better validation and documentation'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecad980",
   "metadata": {},
   "source": [
    "## 3. ü§ñ LLM Integration (Gemini, Claude, Gemma 3n)\n",
    "\n",
    "This is where Copilot Agent becomes essential for implementing secure and efficient LLM integrations.\n",
    "\n",
    "### üîë **Copilot Prompts for LLM Integration**\n",
    "\n",
    "#### **Google Gemini Integration**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "Write a Python class GeminiService that:\n",
    "1. Handles Google Gemini API calls with proper error handling\n",
    "2. Supports both text and multimodal (text + image) requests\n",
    "3. Implements exponential backoff for rate limiting\n",
    "4. Securely manages API keys from environment variables\n",
    "5. Includes logging for debugging and monitoring\n",
    "6. Returns structured responses with metadata\n",
    "```\n",
    "\n",
    "#### **Anthropic Claude Integration**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "Create a ClaudeService class that:\n",
    "1. Integrates with Anthropic's Claude API\n",
    "2. Implements message history for context\n",
    "3. Handles different Claude models (Claude-3, Claude-3.5)\n",
    "4. Includes proper token counting and management\n",
    "5. Provides ethical reasoning capabilities\n",
    "6. Uses async/await for better performance\n",
    "```\n",
    "\n",
    "#### **Gemma 3n Local Integration**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "Design a Gemma3nService using Hugging Face Transformers that:\n",
    "1. Loads the Google Gemma 3n model for local inference\n",
    "2. Supports both text and image inputs\n",
    "3. Optimizes for GPU/CPU usage based on availability\n",
    "4. Implements model caching for better performance\n",
    "5. Provides quantization options for resource efficiency\n",
    "6. Includes safety filters and content moderation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Service Integration Template (Ask Copilot to expand this)\n",
    "# Place in app/services/llm_service.py\n",
    "\n",
    "llm_service_template = '''\n",
    "import asyncio\n",
    "import logging\n",
    "from typing import Optional, Dict, Any, List\n",
    "import google.generativeai as genai\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LLMResponse:\n",
    "    content: str\n",
    "    model_used: str\n",
    "    confidence: float\n",
    "    reasoning: str\n",
    "    token_count: int\n",
    "    processing_time: float\n",
    "\n",
    "class LLMOrchestrator:\n",
    "    \"\"\"\n",
    "    Multi-LLM service orchestrator for EthicCompanion\n",
    "    Copilot Prompt: \"Enhance this class with load balancing and fallback logic\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.gemini_client = self._init_gemini()\n",
    "        self.claude_client = self._init_claude()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def _init_gemini(self):\n",
    "        \"\"\"Initialize Gemini client with API key\"\"\"\n",
    "        api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not api_key:\n",
    "            self.logger.warning(\"Gemini API key not found\")\n",
    "            return None\n",
    "        genai.configure(api_key=api_key)\n",
    "        return genai.GenerativeModel('gemini-pro')\n",
    "    \n",
    "    def _init_claude(self):\n",
    "        \"\"\"Initialize Claude client\"\"\"\n",
    "        api_key = os.getenv(\"CLAUDE_API_KEY\")\n",
    "        if not api_key:\n",
    "            self.logger.warning(\"Claude API key not found\")\n",
    "            return None\n",
    "        return Anthropic(api_key=api_key)\n",
    "    \n",
    "    async def get_ethical_guidance(\n",
    "        self, \n",
    "        query: str, \n",
    "        context: Dict[str, Any] = None,\n",
    "        preferred_model: str = \"gemini\"\n",
    "    ) -> LLMResponse:\n",
    "        \"\"\"\n",
    "        Get ethical guidance using the specified LLM\n",
    "        Copilot Prompt: \"Add intelligent model selection based on query type\"\n",
    "        \"\"\"\n",
    "        # Implementation will be enhanced by Copilot\n",
    "        pass\n",
    "    \n",
    "    async def analyze_sentiment_and_bias(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze text for emotional impact and bias\n",
    "        Copilot Prompt: \"Implement sentiment analysis for news content\"\n",
    "        \"\"\"\n",
    "        pass\n",
    "'''\n",
    "\n",
    "print(\"ü§ñ LLM Service Template:\")\n",
    "print(\"=\" * 50)\n",
    "print(llm_service_template)\n",
    "print(\"\\nüí° Next Copilot Actions:\")\n",
    "print(\"1. 'Complete the get_ethical_guidance method with error handling'\")\n",
    "print(\"2. 'Add retry logic with exponential backoff'\")\n",
    "print(\"3. 'Implement model fallback when primary LLM fails'\")\n",
    "print(\"4. 'Add prompt engineering for better ethical responses'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03682bc4",
   "metadata": {},
   "source": [
    "## 4. üìö RAG Pipeline Implementation with LangChain\n",
    "\n",
    "The RAG (Retrieval-Augmented Generation) pipeline is crucial for grounding AI responses in your ethical knowledge base.\n",
    "\n",
    "### üéØ **Key Copilot Prompts for RAG Implementation**\n",
    "\n",
    "#### **Vector Database Setup**\n",
    "\n",
    "**Copilot Prompt for Document Ingestion:**\n",
    "```\n",
    "Create a Python script that:\n",
    "1. Reads all Markdown files from ethical_knowledge_base/ directory\n",
    "2. Splits documents into semantic chunks using LangChain\n",
    "3. Generates embeddings using Vertex AI Embedding API\n",
    "4. Stores vectors in ChromaDB with metadata\n",
    "5. Implements incremental updates for new documents\n",
    "6. Includes error handling and progress tracking\n",
    "```\n",
    "\n",
    "#### **LangChain RAG Chain Creation**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "Using LangChain, create a RetrievalQA chain that:\n",
    "1. Uses ChromaDB as the vector store retriever\n",
    "2. Integrates with Gemini as the primary LLM\n",
    "3. Implements custom prompt templates for ethical guidance\n",
    "4. Includes source attribution in responses\n",
    "5. Supports query reformulation for better retrieval\n",
    "6. Implements relevance scoring and filtering\n",
    "```\n",
    "\n",
    "#### **Advanced RAG Features**\n",
    "\n",
    "**Copilot Prompts:**\n",
    "```\n",
    "\"Add semantic search with query expansion for better document retrieval\"\n",
    "\"Implement hybrid search combining vector similarity and keyword matching\"\n",
    "\"Create a document ranking system based on ethical principle relevance\"\n",
    "\"Add multi-language support for the knowledge base\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2498ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Pipeline Implementation (Use Copilot to complete)\n",
    "# Place in app/services/rag_service.py\n",
    "\n",
    "rag_implementation_template = '''\n",
    "from langchain.document_loaders import DirectoryLoader, MarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import VertexAI\n",
    "import chromadb\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "class EthicalRAGService:\n",
    "    \"\"\"\n",
    "    RAG service for ethical knowledge retrieval and generation\n",
    "    \n",
    "    Copilot Prompts to enhance this class:\n",
    "    1. \"Add document preprocessing for better semantic chunking\"\n",
    "    2. \"Implement query reformulation for ambiguous ethical questions\"\n",
    "    3. \"Add confidence scoring for retrieved documents\"\n",
    "    4. \"Create custom retrieval strategies for different query types\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, knowledge_base_path: str = \"ethical_knowledge_base\"):\n",
    "        self.knowledge_base_path = Path(knowledge_base_path)\n",
    "        self.embeddings = self._initialize_embeddings()\n",
    "        self.vector_store = self._initialize_vector_store()\n",
    "        self.retrieval_chain = self._create_retrieval_chain()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def _initialize_embeddings(self):\n",
    "        \"\"\"Initialize Vertex AI embeddings\"\"\"\n",
    "        # Copilot Prompt: \"Configure Vertex AI embeddings with optimal parameters\"\n",
    "        return VertexAIEmbeddings(\n",
    "            model_name=\"textembedding-gecko@001\",\n",
    "            project=os.getenv(\"GCP_PROJECT_ID\"),\n",
    "            location=os.getenv(\"VERTEX_AI_LOCATION\", \"us-central1\")\n",
    "        )\n",
    "    \n",
    "    def _initialize_vector_store(self):\n",
    "        \"\"\"Initialize ChromaDB vector store\"\"\"\n",
    "        # Copilot Prompt: \"Set up ChromaDB with persistent storage and collections\"\n",
    "        client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        return Chroma(\n",
    "            client=client,\n",
    "            collection_name=\"ethical_knowledge\",\n",
    "            embedding_function=self.embeddings\n",
    "        )\n",
    "    \n",
    "    def ingest_knowledge_base(self):\n",
    "        \"\"\"\n",
    "        Ingest Markdown documents from knowledge base\n",
    "        \n",
    "        Copilot Prompt: \"Complete this method with document loading and chunking\"\n",
    "        \"\"\"\n",
    "        # Load documents\n",
    "        loader = DirectoryLoader(\n",
    "            str(self.knowledge_base_path),\n",
    "            glob=\"*.md\",\n",
    "            loader_cls=MarkdownLoader\n",
    "        )\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Add to vector store\n",
    "        self.vector_store.add_documents(chunks)\n",
    "        self.logger.info(f\"Ingested {len(chunks)} document chunks\")\n",
    "    \n",
    "    async def get_relevant_context(self, query: str, k: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Copilot Prompt: \"Add semantic similarity scoring and metadata filtering\"\n",
    "        \"\"\"\n",
    "        docs = self.vector_store.similarity_search_with_score(query, k=k)\n",
    "        return [\n",
    "            {\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"relevance_score\": score\n",
    "            }\n",
    "            for doc, score in docs\n",
    "        ]\n",
    "    \n",
    "    async def generate_ethical_guidance(self, query: str, context: str = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate ethical guidance using RAG\n",
    "        \n",
    "        Copilot Prompt: \"Implement ethical prompt templates and response formatting\"\n",
    "        \"\"\"\n",
    "        # Implementation to be completed with Copilot\n",
    "        pass\n",
    "'''\n",
    "\n",
    "print(\"üìö RAG Service Template:\")\n",
    "print(\"=\" * 50)\n",
    "print(rag_implementation_template[:1500] + \"...\")\n",
    "print(\"\\nüéØ Key Copilot Enhancement Areas:\")\n",
    "print(\"1. Document preprocessing and chunking strategies\")\n",
    "print(\"2. Query reformulation and expansion\")\n",
    "print(\"3. Hybrid search (vector + keyword)\")\n",
    "print(\"4. Source attribution and confidence scoring\")\n",
    "print(\"5. Custom retrieval for different ethical domains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624ef4b",
   "metadata": {},
   "source": [
    "## 5. üõ°Ô∏è Ethical Guardrails Implementation\n",
    "\n",
    "Implementing robust ethical guardrails is crucial for ensuring safe and responsible AI interactions.\n",
    "\n",
    "### üîí **Copilot Prompts for Guardrails Implementation**\n",
    "\n",
    "#### **NeMo Guardrails Configuration**\n",
    "\n",
    "**Copilot Prompt for .co file:**\n",
    "```\n",
    "Generate a NeMo Guardrails .co configuration file that:\n",
    "1. Defines topical guardrails for ethical guidance only\n",
    "2. Prohibits political debate and controversial topics\n",
    "3. Ensures conversations stay within mental health and information management\n",
    "4. Includes input/output filtering for harmful content\n",
    "5. Defines appropriate response templates for boundary violations\n",
    "6. Implements escalation procedures for sensitive topics\n",
    "```\n",
    "\n",
    "#### **Content Moderation Integration**\n",
    "\n",
    "**Copilot Prompts:**\n",
    "```\n",
    "\"Create a ContentModerator class that integrates multiple APIs:\n",
    "- Google Perspective API for toxicity detection\n",
    "- OpenAI Moderation API for content policy violations\n",
    "- Custom keyword filtering for ethical boundaries\n",
    "- Sentiment analysis for emotional safety\"\n",
    "\n",
    "\"Implement real-time content filtering for both user inputs and AI outputs with proper logging and escalation\"\n",
    "```\n",
    "\n",
    "#### **Custom Ethical Validators**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "\"Design custom validation functions that:\n",
    "1. Check if queries relate to ethical information management\n",
    "2. Detect requests for medical/legal advice (redirect appropriately)\n",
    "3. Identify crisis situations requiring human intervention\n",
    "4. Validate that responses promote constructive action\n",
    "5. Ensure cultural sensitivity and inclusivity\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113024f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethical Guardrails Implementation Template\n",
    "# Use Copilot to expand these guardrails\n",
    "\n",
    "nemo_guardrails_config = '''\n",
    "# ethiccompanion_guardrails.co - NeMo Guardrails Configuration\n",
    "# Copilot Prompt: \"Enhance this configuration with more comprehensive ethical boundaries\"\n",
    "\n",
    "define user ask_off_topic\n",
    "  \"Can you help me with political opinions?\"\n",
    "  \"What do you think about [political party]?\"\n",
    "  \"Should I invest in cryptocurrency?\"\n",
    "  \"Can you diagnose my symptoms?\"\n",
    "\n",
    "define user ask_ethical_guidance\n",
    "  \"How can I manage information overload?\"\n",
    "  \"I feel overwhelmed by news, what should I do?\"\n",
    "  \"How can I find inner peace?\"\n",
    "  \"What are ethical ways to help during a crisis?\"\n",
    "\n",
    "define bot inform_boundaries\n",
    "  \"I'm designed to help with ethical guidance on information management and finding inner peace. For political, medical, or financial advice, I'd recommend consulting appropriate professionals.\"\n",
    "\n",
    "define flow ethical_guidance_only\n",
    "  user ask_off_topic\n",
    "  bot inform_boundaries\n",
    "  bot offer_help\n",
    "\n",
    "define flow main_ethical_guidance\n",
    "  user ask_ethical_guidance\n",
    "  bot provide_ethical_guidance\n",
    "\n",
    "# Copilot enhancement areas:\n",
    "# 1. Add more nuanced topic detection\n",
    "# 2. Implement context-aware boundaries\n",
    "# 3. Create supportive redirection messages\n",
    "# 4. Add crisis intervention protocols\n",
    "'''\n",
    "\n",
    "guardrails_service_template = '''\n",
    "from typing import Dict, List, Any, Optional\n",
    "import logging\n",
    "from googleapiclient import discovery\n",
    "import openai\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModerationResult:\n",
    "    is_safe: bool\n",
    "    flags: List[str]\n",
    "    confidence: float\n",
    "    explanation: str\n",
    "\n",
    "class EthicalGuardrailsService:\n",
    "    \"\"\"\n",
    "    Comprehensive content moderation and ethical boundary enforcement\n",
    "    \n",
    "    Copilot Prompts:\n",
    "    1. \"Add multilingual toxicity detection\"\n",
    "    2. \"Implement progressive warning system\"\n",
    "    3. \"Create ethical conversation steering\"\n",
    "    4. \"Add crisis detection and intervention\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.perspective_client = self._init_perspective_api()\n",
    "        self.openai_client = self._init_openai_client()\n",
    "        self.ethical_keywords = self._load_ethical_keywords()\n",
    "        self.crisis_keywords = self._load_crisis_keywords()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    async def moderate_content(self, text: str) -> ModerationResult:\n",
    "        \"\"\"\n",
    "        Comprehensive content moderation\n",
    "        Copilot Prompt: \"Implement multi-API content moderation with fallbacks\"\n",
    "        \"\"\"\n",
    "        # Check for toxicity\n",
    "        toxicity_score = await self._check_toxicity(text)\n",
    "        \n",
    "        # Check for policy violations\n",
    "        policy_violations = await self._check_policy_violations(text)\n",
    "        \n",
    "        # Check ethical boundaries\n",
    "        ethical_assessment = self._assess_ethical_boundaries(text)\n",
    "        \n",
    "        # Crisis detection\n",
    "        crisis_indicators = self._detect_crisis_situations(text)\n",
    "        \n",
    "        # Combine results\n",
    "        return self._combine_moderation_results(\n",
    "            toxicity_score, policy_violations, ethical_assessment, crisis_indicators\n",
    "        )\n",
    "    \n",
    "    def _assess_ethical_boundaries(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Assess if content aligns with ethical guidance scope\n",
    "        Copilot Prompt: \"Create sophisticated ethical boundary detection\"\n",
    "        \"\"\"\n",
    "        # Implementation to be enhanced by Copilot\n",
    "        pass\n",
    "    \n",
    "    def steer_conversation_ethically(self, user_query: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Provide gentle redirection for off-topic queries\n",
    "        Copilot Prompt: \"Generate empathetic redirection messages\"\n",
    "        \"\"\"\n",
    "        # Implementation to be enhanced by Copilot\n",
    "        pass\n",
    "'''\n",
    "\n",
    "print(\"üõ°Ô∏è Ethical Guardrails Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"NeMo Guardrails Config Sample:\")\n",
    "print(nemo_guardrails_config[:800] + \"...\")\n",
    "print(\"\\nüîß Guardrails Service Template:\")\n",
    "print(guardrails_service_template[:600] + \"...\")\n",
    "print(\"\\nüí° Key Copilot Enhancement Areas:\")\n",
    "print(\"1. Multi-API content moderation with intelligent fallbacks\")\n",
    "print(\"2. Context-aware ethical boundary detection\")\n",
    "print(\"3. Crisis intervention and escalation protocols\")\n",
    "print(\"4. Supportive conversation steering and redirection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a75f2",
   "metadata": {},
   "source": [
    "## 6. üì± Frontend Development - Flutter Chat UI\n",
    "\n",
    "Now we'll enhance the Flutter frontend using Copilot Agent to create an intuitive and beautiful chat interface.\n",
    "\n",
    "### üé® **Copilot Prompts for Flutter UI Development**\n",
    "\n",
    "#### **Enhanced Chat Screen**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "Create a Flutter StatefulWidget for a modern chat screen that includes:\n",
    "1. App bar with EthicCompanion branding and status indicator\n",
    "2. Scrollable ListView.builder for message history with auto-scroll\n",
    "3. Text input field with multi-line support and character counter\n",
    "4. Send button with loading states and animations\n",
    "5. Typing indicator for AI responses\n",
    "6. Pull-to-refresh for conversation history\n",
    "7. Floating action button for quick peace techniques\n",
    "8. Dark/light theme support\n",
    "```\n",
    "\n",
    "#### **Advanced Message Components**\n",
    "\n",
    "**Copilot Prompts:**\n",
    "```\n",
    "\"Generate Flutter widgets for different message types:\n",
    "- User text messages with timestamp\n",
    "- AI ethical guidance with source citations\n",
    "- Peace technique cards with expandable content\n",
    "- Action suggestion buttons with tap handlers\n",
    "- Error messages with retry functionality\n",
    "- System messages for boundary explanations\"\n",
    "\n",
    "\"Create animated message bubbles with:\n",
    "- Smooth appearance animations\n",
    "- Different styles for user vs AI messages\n",
    "- Syntax highlighting for structured advice\n",
    "- Copy-to-clipboard functionality\n",
    "- Message reaction buttons (helpful/not helpful)\"\n",
    "```\n",
    "\n",
    "#### **State Management Integration**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "Design a Provider-based state management system that:\n",
    "1. Manages chat message list with proper immutability\n",
    "2. Handles API call states (loading, success, error)\n",
    "3. Persists conversation history locally\n",
    "4. Manages user preferences and settings\n",
    "5. Implements offline mode with cached responses\n",
    "6. Handles real-time typing indicators\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flutter Implementation Templates (Use Copilot to expand these)\n",
    "\n",
    "flutter_chat_screen_template = '''\n",
    "// lib/screens/chat_screen.dart\n",
    "// Copilot Prompt: \"Complete this Flutter chat screen with modern Material Design 3\"\n",
    "\n",
    "import 'package:flutter/material.dart';\n",
    "import 'package:provider/provider.dart';\n",
    "import '../models/message.dart';\n",
    "import '../providers/chat_provider.dart';\n",
    "import '../widgets/message_bubble.dart';\n",
    "import '../widgets/typing_indicator.dart';\n",
    "\n",
    "class ChatScreen extends StatefulWidget {\n",
    "  @override\n",
    "  _ChatScreenState createState() => _ChatScreenState();\n",
    "}\n",
    "\n",
    "class _ChatScreenState extends State<ChatScreen> with TickerProviderStateMixin {\n",
    "  final TextEditingController _textController = TextEditingController();\n",
    "  final ScrollController _scrollController = ScrollController();\n",
    "  late AnimationController _animationController;\n",
    "\n",
    "  @override\n",
    "  void initState() {\n",
    "    super.initState();\n",
    "    _animationController = AnimationController(\n",
    "      duration: Duration(milliseconds: 300),\n",
    "      vsync: this,\n",
    "    );\n",
    "    \n",
    "    // Copilot enhancement: Add auto-scroll behavior\n",
    "    // Copilot enhancement: Load conversation history\n",
    "    // Copilot enhancement: Set up typing indicators\n",
    "  }\n",
    "\n",
    "  @override\n",
    "  Widget build(BuildContext context) {\n",
    "    return Scaffold(\n",
    "      appBar: AppBar(\n",
    "        title: Row(\n",
    "          children: [\n",
    "            Icon(Icons.psychology, color: Colors.green),\n",
    "            SizedBox(width: 8),\n",
    "            Text('EthicCompanion'),\n",
    "            // Copilot: Add status indicator\n",
    "          ],\n",
    "        ),\n",
    "        actions: [\n",
    "          // Copilot: Add settings and info buttons\n",
    "        ],\n",
    "      ),\n",
    "      body: Column(\n",
    "        children: [\n",
    "          // Message list\n",
    "          Expanded(\n",
    "            child: Consumer<ChatProvider>(\n",
    "              builder: (context, chatProvider, child) {\n",
    "                return ListView.builder(\n",
    "                  controller: _scrollController,\n",
    "                  padding: EdgeInsets.all(16),\n",
    "                  itemCount: chatProvider.messages.length + \n",
    "                           (chatProvider.isTyping ? 1 : 0),\n",
    "                  itemBuilder: (context, index) {\n",
    "                    // Copilot: Implement message rendering logic\n",
    "                    // Copilot: Add typing indicator at end\n",
    "                    return Container(); // Placeholder\n",
    "                  },\n",
    "                );\n",
    "              },\n",
    "            ),\n",
    "          ),\n",
    "          // Input area\n",
    "          _buildInputArea(),\n",
    "        ],\n",
    "      ),\n",
    "      floatingActionButton: FloatingActionButton(\n",
    "        onPressed: () {\n",
    "          // Copilot: Show quick peace techniques bottom sheet\n",
    "        },\n",
    "        child: Icon(Icons.self_improvement),\n",
    "        tooltip: 'Quick Peace Techniques',\n",
    "      ),\n",
    "    );\n",
    "  }\n",
    "\n",
    "  Widget _buildInputArea() {\n",
    "    // Copilot Prompt: \"Create a sophisticated input area with:\n",
    "    // - Multi-line text input with character counter\n",
    "    // - Send button with loading states\n",
    "    // - Voice input capability (future enhancement)\n",
    "    // - Attachment support for images\"\n",
    "    return Container(); // Placeholder for Copilot expansion\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "flutter_api_service_template = '''\n",
    "// lib/services/api_service.dart\n",
    "// Copilot Prompt: \"Complete this API service with proper error handling and retry logic\"\n",
    "\n",
    "import 'dart:convert';\n",
    "import 'dart:io';\n",
    "import 'package:http/http.dart' as http;\n",
    "import '../models/message.dart';\n",
    "\n",
    "class ApiService {\n",
    "  static const String baseUrl = 'http://127.0.0.1:8000';\n",
    "  late http.Client _client;\n",
    "\n",
    "  ApiService() {\n",
    "    _client = http.Client();\n",
    "  }\n",
    "\n",
    "  Future<EthicalResponse> askEthicalQuestion({\n",
    "    required String query,\n",
    "    String? imageData,\n",
    "    String? context,\n",
    "  }) async {\n",
    "    // Copilot Prompt: \"Implement robust API call with:\n",
    "    // - Proper request formatting\n",
    "    // - Timeout handling\n",
    "    // - Retry logic with exponential backoff\n",
    "    // - Comprehensive error handling\n",
    "    // - Progress callbacks for UI updates\"\n",
    "    \n",
    "    try {\n",
    "      final response = await _client.post(\n",
    "        Uri.parse('$baseUrl/ask_ethical'),\n",
    "        headers: {\n",
    "          'Content-Type': 'application/json',\n",
    "        },\n",
    "        body: jsonEncode({\n",
    "          'user_query': query,\n",
    "          'image_data': imageData,\n",
    "          'context': context ?? {},\n",
    "        }),\n",
    "      ).timeout(Duration(seconds: 30));\n",
    "\n",
    "      if (response.statusCode == 200) {\n",
    "        final Map<String, dynamic> data = jsonDecode(response.body);\n",
    "        return EthicalResponse.fromJson(data);\n",
    "      } else {\n",
    "        throw ApiException('Server error: ${response.statusCode}');\n",
    "      }\n",
    "    } catch (e) {\n",
    "      // Copilot: Add sophisticated error handling\n",
    "      rethrow;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  Future<List<PeaceTechnique>> getPeaceTechniques({\n",
    "    required String stressLevel,\n",
    "    int? timeAvailable,\n",
    "  }) async {\n",
    "    // Copilot: Implement peace techniques API call\n",
    "    return [];\n",
    "  }\n",
    "\n",
    "  void dispose() {\n",
    "    _client.close();\n",
    "  }\n",
    "}\n",
    "\n",
    "class ApiException implements Exception {\n",
    "  final String message;\n",
    "  ApiException(this.message);\n",
    "}\n",
    "'''\n",
    "\n",
    "print(\"üì± Flutter Implementation Templates:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Chat Screen Template (partial):\")\n",
    "print(flutter_chat_screen_template[:1200] + \"...\")\n",
    "print(\"\\nAPI Service Template (partial):\")\n",
    "print(flutter_api_service_template[:1000] + \"...\")\n",
    "print(\"\\nüéØ Key Copilot Enhancement Areas for Flutter:\")\n",
    "print(\"1. Modern Material Design 3 implementation\")\n",
    "print(\"2. Smooth animations and micro-interactions\")\n",
    "print(\"3. Robust state management with Provider/Riverpod\")\n",
    "print(\"4. Comprehensive error handling and offline support\")\n",
    "print(\"5. Accessibility features and internationalization\")\n",
    "print(\"6. Performance optimization for large conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db48199",
   "metadata": {},
   "source": [
    "## 7. üß™ Testing and Debugging Workflows\n",
    "\n",
    "Comprehensive testing is crucial for a reliable hackathon submission. Copilot Agent will help create robust test suites.\n",
    "\n",
    "### üîç **Copilot Prompts for Backend Testing**\n",
    "\n",
    "#### **Unit Tests for Core Services**\n",
    "\n",
    "**Copilot Prompts:**\n",
    "```\n",
    "\"Create pytest unit tests for the EthicalRAGService that:\n",
    "1. Mock external API calls (Gemini, Claude, Vector DB)\n",
    "2. Test document ingestion and retrieval accuracy\n",
    "3. Validate response formatting and structure\n",
    "4. Test error handling for various failure scenarios\n",
    "5. Include performance benchmarks for response time\"\n",
    "\n",
    "\"Generate unit tests for the EthicalGuardrailsService:\n",
    "1. Test content moderation with various input types\n",
    "2. Validate ethical boundary detection accuracy\n",
    "3. Test crisis intervention triggers\n",
    "4. Mock external moderation APIs\n",
    "5. Test conversation steering functionality\"\n",
    "```\n",
    "\n",
    "#### **Integration Testing**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "\"Create integration tests that:\n",
    "1. Test the full API pipeline from request to response\n",
    "2. Validate RAG + LLM + Guardrails integration\n",
    "3. Test database persistence and retrieval\n",
    "4. Validate API rate limiting and error responses\n",
    "5. Test multimodal inputs (text + image)\n",
    "6. Include load testing for expected user volumes\"\n",
    "```\n",
    "\n",
    "### üì± **Flutter Testing with Copilot**\n",
    "\n",
    "**Copilot Prompts:**\n",
    "```\n",
    "\"Generate Flutter widget tests for:\n",
    "1. ChatScreen user interactions and state changes\n",
    "2. MessageBubble rendering with different message types\n",
    "3. API service error handling and retry logic\n",
    "4. Provider state management accuracy\n",
    "5. Navigation and routing functionality\"\n",
    "\n",
    "\"Create Flutter integration tests that:\n",
    "1. Test complete user conversation flows\n",
    "2. Validate offline mode functionality\n",
    "3. Test theme switching and accessibility\n",
    "4. Simulate network failures and recovery\n",
    "5. Test conversation persistence across app restarts\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Implementation Templates (Expand with Copilot)\n",
    "\n",
    "pytest_backend_template = '''\n",
    "# tests/test_rag_service.py\n",
    "# Copilot Prompt: \"Complete this test suite with comprehensive mocking and assertions\"\n",
    "\n",
    "import pytest\n",
    "from unittest.mock import Mock, patch, AsyncMock\n",
    "import asyncio\n",
    "from app.services.rag_service import EthicalRAGService\n",
    "from app.models.chat_models import EthicalRequest, EthicalResponse\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_rag_service():\n",
    "    \"\"\"\n",
    "    Mock RAG service for testing\n",
    "    Copilot: Enhance this fixture with realistic mock data\n",
    "    \"\"\"\n",
    "    with patch('app.services.rag_service.VertexAIEmbeddings') as mock_embeddings, \\\n",
    "         patch('app.services.rag_service.Chroma') as mock_vector_store:\n",
    "        \n",
    "        mock_embeddings.return_value = Mock()\n",
    "        mock_vector_store.return_value = Mock()\n",
    "        \n",
    "        service = EthicalRAGService()\n",
    "        return service\n",
    "\n",
    "@pytest.mark.asyncio\n",
    "async def test_get_relevant_context(mock_rag_service):\n",
    "    \"\"\"\n",
    "    Test context retrieval from vector database\n",
    "    Copilot: Add more comprehensive test scenarios\n",
    "    \"\"\"\n",
    "    # Arrange\n",
    "    query = \"How can I manage information overload?\"\n",
    "    expected_docs = [\n",
    "        {\n",
    "            \"content\": \"Information overload occurs when...\",\n",
    "            \"metadata\": {\"source\": \"information_overload_guide.md\"},\n",
    "            \"relevance_score\": 0.85\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    mock_rag_service.vector_store.similarity_search_with_score.return_value = [\n",
    "        (Mock(page_content=expected_docs[0][\"content\"], \n",
    "              metadata=expected_docs[0][\"metadata\"]), \n",
    "         expected_docs[0][\"relevance_score\"])\n",
    "    ]\n",
    "    \n",
    "    # Act\n",
    "    result = await mock_rag_service.get_relevant_context(query, k=1)\n",
    "    \n",
    "    # Assert\n",
    "    assert len(result) == 1\n",
    "    assert result[0][\"content\"] == expected_docs[0][\"content\"]\n",
    "    assert result[0][\"relevance_score\"] == expected_docs[0][\"relevance_score\"]\n",
    "    \n",
    "    # Copilot: Add more test cases for edge scenarios\n",
    "\n",
    "@pytest.mark.asyncio\n",
    "async def test_ethical_guardrails_integration():\n",
    "    \"\"\"\n",
    "    Test guardrails integration with RAG responses\n",
    "    Copilot: Implement comprehensive guardrails testing\n",
    "    \"\"\"\n",
    "    # Copilot will help implement this test\n",
    "    pass\n",
    "\n",
    "class TestEthicalEndpoints:\n",
    "    \"\"\"\n",
    "    Integration tests for FastAPI endpoints\n",
    "    Copilot: Generate comprehensive API testing scenarios\n",
    "    \"\"\"\n",
    "    \n",
    "    @pytest.mark.asyncio\n",
    "    async def test_ask_ethical_endpoint_success(self, test_client):\n",
    "        \"\"\"Test successful ethical guidance request\"\"\"\n",
    "        # Copilot: Implement full API testing\n",
    "        pass\n",
    "    \n",
    "    @pytest.mark.asyncio\n",
    "    async def test_ask_ethical_endpoint_rate_limiting(self, test_client):\n",
    "        \"\"\"Test rate limiting functionality\"\"\"\n",
    "        # Copilot: Implement rate limiting tests\n",
    "        pass\n",
    "'''\n",
    "\n",
    "flutter_test_template = '''\n",
    "// test/widget_test.dart\n",
    "// Copilot Prompt: \"Create comprehensive Flutter widget tests with proper mocking\"\n",
    "\n",
    "import 'package:flutter/material.dart';\n",
    "import 'package:flutter_test/flutter_test.dart';\n",
    "import 'package:provider/provider.dart';\n",
    "import 'package:mockito/mockito.dart';\n",
    "import 'package:ethiccompanion/screens/chat_screen.dart';\n",
    "import 'package:ethiccompanion/providers/chat_provider.dart';\n",
    "import 'package:ethiccompanion/services/api_service.dart';\n",
    "\n",
    "class MockApiService extends Mock implements ApiService {}\n",
    "class MockChatProvider extends Mock implements ChatProvider {}\n",
    "\n",
    "void main() {\n",
    "  group('ChatScreen Widget Tests', () {\n",
    "    late MockApiService mockApiService;\n",
    "    late MockChatProvider mockChatProvider;\n",
    "\n",
    "    setUp(() {\n",
    "      mockApiService = MockApiService();\n",
    "      mockChatProvider = MockChatProvider();\n",
    "      \n",
    "      // Copilot: Set up default mock behaviors\n",
    "    });\n",
    "\n",
    "    testWidgets('displays chat interface correctly', (WidgetTester tester) async {\n",
    "      // Arrange\n",
    "      when(mockChatProvider.messages).thenReturn([]);\n",
    "      when(mockChatProvider.isTyping).thenReturn(false);\n",
    "\n",
    "      // Act\n",
    "      await tester.pumpWidget(\n",
    "        MaterialApp(\n",
    "          home: ChangeNotifierProvider<ChatProvider>.value(\n",
    "            value: mockChatProvider,\n",
    "            child: ChatScreen(),\n",
    "          ),\n",
    "        ),\n",
    "      );\n",
    "\n",
    "      // Assert\n",
    "      expect(find.text('EthicCompanion'), findsOneWidget);\n",
    "      expect(find.byType(TextFormField), findsOneWidget);\n",
    "      expect(find.byType(FloatingActionButton), findsOneWidget);\n",
    "      \n",
    "      // Copilot: Add more comprehensive UI assertions\n",
    "    });\n",
    "\n",
    "    testWidgets('sends message when send button is tapped', (WidgetTester tester) async {\n",
    "      // Copilot: Implement user interaction testing\n",
    "    });\n",
    "\n",
    "    testWidgets('displays typing indicator when AI is responding', (WidgetTester tester) async {\n",
    "      // Copilot: Test typing indicator functionality\n",
    "    });\n",
    "  });\n",
    "\n",
    "  group('Integration Tests', () {\n",
    "    testWidgets('complete conversation flow test', (WidgetTester tester) async {\n",
    "      // Copilot: Implement end-to-end conversation testing\n",
    "    });\n",
    "  });\n",
    "}\n",
    "'''\n",
    "\n",
    "print(\"üß™ Testing Implementation Templates:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Backend Testing (pytest):\")\n",
    "print(pytest_backend_template[:1500] + \"...\")\n",
    "print(\"\\nFlutter Testing:\")\n",
    "print(flutter_test_template[:1500] + \"...\")\n",
    "print(\"\\nüéØ Testing Strategy with Copilot:\")\n",
    "print(\"1. Unit tests for all service layers\")\n",
    "print(\"2. Integration tests for API endpoints\")\n",
    "print(\"3. Widget tests for Flutter components\") \n",
    "print(\"4. End-to-end conversation flow tests\")\n",
    "print(\"5. Performance and load testing\")\n",
    "print(\"6. Error scenario and edge case testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a146557",
   "metadata": {},
   "source": [
    "## 8. üìñ Documentation Generation & Hackathon Strategy\n",
    "\n",
    "Perfect documentation is crucial for hackathon success. Copilot Agent will help create compelling technical documentation and demo materials.\n",
    "\n",
    "### üìù **Copilot Prompts for Documentation**\n",
    "\n",
    "#### **Enhanced README.md**\n",
    "\n",
    "**Copilot Prompts:**\n",
    "```\n",
    "\"Expand the 'Gemma 3n Integration' section in README.md to highlight:\n",
    "1. How Gemma 3n's multimodal capabilities enhance ethical guidance\n",
    "2. Performance optimizations for real-time inference\n",
    "3. Privacy benefits of local model deployment\n",
    "4. Comparison with cloud-based alternatives\n",
    "5. Technical implementation details with code snippets\"\n",
    "\n",
    "\"Create a comprehensive 'Architecture Overview' section that:\n",
    "1. Includes system architecture diagrams (suggest ASCII art)\n",
    "2. Explains the RAG pipeline with data flow\n",
    "3. Details the ethical guardrails implementation\n",
    "4. Shows integration points between all components\n",
    "5. Highlights scalability and security considerations\"\n",
    "```\n",
    "\n",
    "#### **Technical Demo Script**\n",
    "\n",
    "**Copilot Prompt:**\n",
    "```\n",
    "\"Generate a 3-minute video demo script that:\n",
    "1. Opens with the information overload problem (30 seconds)\n",
    "2. Demonstrates EthicCompanion solving real user scenarios (90 seconds)\n",
    "3. Highlights Gemma 3n's unique capabilities (45 seconds)\n",
    "4. Shows measurable impact and future vision (15 seconds)\n",
    "Include specific dialogue and visual cues for each segment\"\n",
    "```\n",
    "\n",
    "#### **API Documentation**\n",
    "\n",
    "**Copilot Prompts:**\n",
    "```\n",
    "\"Create comprehensive API documentation including:\n",
    "1. Interactive examples for each endpoint\n",
    "2. Request/response schemas with validation rules\n",
    "3. Error codes and troubleshooting guide\n",
    "4. Rate limiting and authentication details\n",
    "5. SDK examples in Python and JavaScript\"\n",
    "```\n",
    "\n",
    "### üéØ **Strategic Implementation Roadmap**\n",
    "\n",
    "Based on your excellent plan, here's how to successfully implement using Copilot Agent:\n",
    "\n",
    "1. **Immediate Actions (Week 1)**\n",
    "2. **Development Sprint (Week 2-3)**\n",
    "3. **Integration & Testing (Week 4)**\n",
    "4. **Demo Preparation (Final Week)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bfcc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Strategic Implementation Roadmap:\n",
      "============================================================\n",
      "\n",
      "üìÖ Week 1 Foundation:\n",
      "  üîß Backend Enhancement:\n",
      "    ‚Ä¢ Use Copilot to enhance existing FastAPI endpoints\n",
      "    ‚Ä¢ Implement advanced Pydantic models with validation\n",
      "    ‚Ä¢ Integrate LLM services (Gemini, Claude, Gemma 3n)\n",
      "    ‚Ä¢ ... and 1 more\n",
      "  üîß Key Copilot Prompts:\n",
      "    ‚Ä¢ 'Enhance my FastAPI endpoint with comprehensive error handling'\n",
      "    ‚Ä¢ 'Create Pydantic models for ethical guidance with validation'\n",
      "    ‚Ä¢ 'Implement secure API key management for multiple LLMs'\n",
      "    ‚Ä¢ ... and 1 more\n",
      "\n",
      "üìÖ Week 2 3 Development:\n",
      "  üîß RAG Pipeline:\n",
      "    ‚Ä¢ Complete document ingestion using Copilot guidance\n",
      "    ‚Ä¢ Implement semantic search with LangChain\n",
      "    ‚Ä¢ Create ethical guardrails with NeMo\n",
      "    ‚Ä¢ ... and 1 more\n",
      "  üîß Frontend Development:\n",
      "    ‚Ä¢ Use Copilot to build Flutter chat interface\n",
      "    ‚Ä¢ Implement state management with Provider\n",
      "    ‚Ä¢ Create beautiful message components\n",
      "    ‚Ä¢ ... and 1 more\n",
      "  üîß Key Copilot Prompts:\n",
      "    ‚Ä¢ 'Create LangChain RetrievalQA with custom prompts'\n",
      "    ‚Ä¢ 'Build Flutter chat UI with Material Design 3'\n",
      "    ‚Ä¢ 'Implement Provider pattern for chat state management'\n",
      "    ‚Ä¢ ... and 1 more\n",
      "\n",
      "üìÖ Week 4 Integration:\n",
      "  üîß System Integration:\n",
      "    ‚Ä¢ Connect Flutter frontend to FastAPI backend\n",
      "    ‚Ä¢ Implement comprehensive testing with Copilot\n",
      "    ‚Ä¢ Add monitoring and logging\n",
      "    ‚Ä¢ ... and 1 more\n",
      "  üîß Testing Strategy:\n",
      "    ‚Ä¢ Unit tests for all backend services\n",
      "    ‚Ä¢ Widget tests for Flutter components\n",
      "    ‚Ä¢ Integration tests for full conversation flows\n",
      "    ‚Ä¢ ... and 1 more\n",
      "  üîß Key Copilot Prompts:\n",
      "    ‚Ä¢ 'Create comprehensive test suite for ethical guidance API'\n",
      "    ‚Ä¢ 'Implement Flutter integration tests for chat flows'\n",
      "    ‚Ä¢ 'Add performance monitoring and logging'\n",
      "    ‚Ä¢ ... and 1 more\n",
      "\n",
      "üìÖ Final Week Demo:\n",
      "  üîß Documentation:\n",
      "    ‚Ä¢ Enhanced README with Gemma 3n highlights\n",
      "    ‚Ä¢ Technical architecture documentation\n",
      "    ‚Ä¢ API documentation with examples\n",
      "    ‚Ä¢ ... and 1 more\n",
      "  üîß Demo Preparation:\n",
      "    ‚Ä¢ Create compelling user scenarios\n",
      "    ‚Ä¢ Prepare backup plans for live demo\n",
      "    ‚Ä¢ Test on different devices and networks\n",
      "    ‚Ä¢ ... and 1 more\n",
      "  üîß Key Copilot Prompts:\n",
      "    ‚Ä¢ 'Write compelling README highlighting Gemma 3n impact'\n",
      "    ‚Ä¢ 'Generate 3-minute demo script with technical highlights'\n",
      "    ‚Ä¢ 'Create troubleshooting guide for common demo issues'\n",
      "    ‚Ä¢ ... and 1 more\n",
      "\n",
      "üèÜ Success Factors:\n",
      "\n",
      "  üìà Copilot Agent Advantages:\n",
      "    ‚úÖ Rapid prototyping and iteration cycles\n",
      "    ‚úÖ Consistent code quality and documentation\n",
      "    ‚úÖ Comprehensive error handling and edge cases\n",
      "    ‚úÖ Best practices implementation across stack\n",
      "    ‚úÖ Quick debugging and troubleshooting\n",
      "\n",
      "  üìà Competitive Edge:\n",
      "    ‚úÖ Focus on ethical AI with practical applications\n",
      "    ‚úÖ Multimodal Gemma 3n integration for enhanced UX\n",
      "    ‚úÖ Comprehensive guardrails for responsible AI\n",
      "    ‚úÖ Beautiful, intuitive Flutter interface\n",
      "    ‚úÖ Strong technical documentation and testing\n",
      "\n",
      "  üìà Risk Mitigation:\n",
      "    ‚úÖ Multiple LLM providers for redundancy\n",
      "    ‚úÖ Offline mode for demo reliability\n",
      "    ‚úÖ Comprehensive testing to prevent failures\n",
      "    ‚úÖ Clear boundary setting for ethical scope\n",
      "    ‚úÖ Fallback strategies for technical issues\n",
      "\n",
      "üöÄ Implementation Success Strategy:\n",
      "1. Leverage existing working foundation (FastAPI server running)\n",
      "2. Use Copilot Agent for rapid, high-quality development\n",
      "3. Focus on demo-ready features with proper testing\n",
      "4. Create compelling documentation highlighting Gemma 3n\n",
      "5. Prepare for various demo scenarios and edge cases\n",
      "\n",
      "‚ú® Your foundation is solid - now use Copilot Agent to accelerate to victory!\n"
     ]
    }
   ],
   "source": [
    "# Strategic Implementation Plan for Hackathon Success\n",
    "\n",
    "implementation_roadmap = {\n",
    "    \"Week_1_Foundation\": {\n",
    "        \"Backend_Enhancement\": [\n",
    "            \"Use Copilot to enhance existing FastAPI endpoints\",\n",
    "            \"Implement advanced Pydantic models with validation\",\n",
    "            \"Integrate LLM services (Gemini, Claude, Gemma 3n)\",\n",
    "            \"Set up ChromaDB and document ingestion pipeline\"\n",
    "        ],\n",
    "        \"Key_Copilot_Prompts\": [\n",
    "            \"'Enhance my FastAPI endpoint with comprehensive error handling'\",\n",
    "            \"'Create Pydantic models for ethical guidance with validation'\",\n",
    "            \"'Implement secure API key management for multiple LLMs'\",\n",
    "            \"'Design ChromaDB schema for ethical knowledge storage'\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"Week_2_3_Development\": {\n",
    "        \"RAG_Pipeline\": [\n",
    "            \"Complete document ingestion using Copilot guidance\",\n",
    "            \"Implement semantic search with LangChain\",\n",
    "            \"Create ethical guardrails with NeMo\",\n",
    "            \"Integrate content moderation APIs\"\n",
    "        ],\n",
    "        \"Frontend_Development\": [\n",
    "            \"Use Copilot to build Flutter chat interface\",\n",
    "            \"Implement state management with Provider\",\n",
    "            \"Create beautiful message components\",\n",
    "            \"Add offline support and error handling\"\n",
    "        ],\n",
    "        \"Key_Copilot_Prompts\": [\n",
    "            \"'Create LangChain RetrievalQA with custom prompts'\",\n",
    "            \"'Build Flutter chat UI with Material Design 3'\",\n",
    "            \"'Implement Provider pattern for chat state management'\",\n",
    "            \"'Add offline mode with local storage persistence'\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"Week_4_Integration\": {\n",
    "        \"System_Integration\": [\n",
    "            \"Connect Flutter frontend to FastAPI backend\",\n",
    "            \"Implement comprehensive testing with Copilot\",\n",
    "            \"Add monitoring and logging\",\n",
    "            \"Optimize performance for demo\"\n",
    "        ],\n",
    "        \"Testing_Strategy\": [\n",
    "            \"Unit tests for all backend services\",\n",
    "            \"Widget tests for Flutter components\",\n",
    "            \"Integration tests for full conversation flows\",\n",
    "            \"Load testing for expected demo traffic\"\n",
    "        ],\n",
    "        \"Key_Copilot_Prompts\": [\n",
    "            \"'Create comprehensive test suite for ethical guidance API'\",\n",
    "            \"'Implement Flutter integration tests for chat flows'\",\n",
    "            \"'Add performance monitoring and logging'\",\n",
    "            \"'Optimize API response times for real-time demo'\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"Final_Week_Demo\": {\n",
    "        \"Documentation\": [\n",
    "            \"Enhanced README with Gemma 3n highlights\",\n",
    "            \"Technical architecture documentation\",\n",
    "            \"API documentation with examples\",\n",
    "            \"Demo script and presentation materials\"\n",
    "        ],\n",
    "        \"Demo_Preparation\": [\n",
    "            \"Create compelling user scenarios\",\n",
    "            \"Prepare backup plans for live demo\",\n",
    "            \"Test on different devices and networks\",\n",
    "            \"Practice presentation timing\"\n",
    "        ],\n",
    "        \"Key_Copilot_Prompts\": [\n",
    "            \"'Write compelling README highlighting Gemma 3n impact'\",\n",
    "            \"'Generate 3-minute demo script with technical highlights'\",\n",
    "            \"'Create troubleshooting guide for common demo issues'\",\n",
    "            \"'Design presentation slides emphasizing ethical AI innovation'\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "success_factors = {\n",
    "    \"Copilot_Agent_Advantages\": [\n",
    "        \"Rapid prototyping and iteration cycles\",\n",
    "        \"Consistent code quality and documentation\",\n",
    "        \"Comprehensive error handling and edge cases\",\n",
    "        \"Best practices implementation across stack\",\n",
    "        \"Quick debugging and troubleshooting\"\n",
    "    ],\n",
    "    \n",
    "    \"Competitive_Edge\": [\n",
    "        \"Focus on ethical AI with practical applications\",\n",
    "        \"Multimodal Gemma 3n integration for enhanced UX\",\n",
    "        \"Comprehensive guardrails for responsible AI\",\n",
    "        \"Beautiful, intuitive Flutter interface\",\n",
    "        \"Strong technical documentation and testing\"\n",
    "    ],\n",
    "    \n",
    "    \"Risk_Mitigation\": [\n",
    "        \"Multiple LLM providers for redundancy\",\n",
    "        \"Offline mode for demo reliability\",\n",
    "        \"Comprehensive testing to prevent failures\",\n",
    "        \"Clear boundary setting for ethical scope\",\n",
    "        \"Fallback strategies for technical issues\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üéØ Strategic Implementation Roadmap:\")\n",
    "print(\"=\" * 60)\n",
    "for week, tasks in implementation_roadmap.items():\n",
    "    print(f\"\\nüìÖ {week.replace('_', ' ').title()}:\")\n",
    "    for category, items in tasks.items():\n",
    "        print(f\"  üîß {category.replace('_', ' ')}:\")\n",
    "        for item in items[:3]:  # Show first 3 items\n",
    "            print(f\"    ‚Ä¢ {item}\")\n",
    "        if len(items) > 3:\n",
    "            print(f\"    ‚Ä¢ ... and {len(items)-3} more\")\n",
    "\n",
    "print(f\"\\nüèÜ Success Factors:\")\n",
    "for category, factors in success_factors.items():\n",
    "    print(f\"\\n  üìà {category.replace('_', ' ')}:\")\n",
    "    for factor in factors:\n",
    "        print(f\"    ‚úÖ {factor}\")\n",
    "\n",
    "print(f\"\\nüöÄ Implementation Success Strategy:\")\n",
    "print(\"1. Leverage existing working foundation (FastAPI server running)\")\n",
    "print(\"2. Use Copilot Agent for rapid, high-quality development\")\n",
    "print(\"3. Focus on demo-ready features with proper testing\")\n",
    "print(\"4. Create compelling documentation highlighting Gemma 3n\")\n",
    "print(\"5. Prepare for various demo scenarios and edge cases\")\n",
    "print(\"\\n‚ú® Your foundation is solid - now use Copilot Agent to accelerate to victory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa1317",
   "metadata": {},
   "source": [
    "## üéØ Ready to Execute: Next Steps with GitHub Copilot Agent\n",
    "\n",
    "Your EthicCompanion foundation is **perfectly positioned** for rapid development success! Here's your strategic advantage:\n",
    "\n",
    "### ‚úÖ Current Strengths\n",
    "- **FastAPI backend running** (localhost:8000)\n",
    "- **All dependencies installed** (ChromaDB, LangChain, NeMo, etc.)\n",
    "- **Complete English knowledge base** ready for ingestion\n",
    "- **Flutter structure** prepared for UI development\n",
    "- **Ethical framework** documented and translated\n",
    "\n",
    "### üöÄ Immediate Actions Using Copilot Agent\n",
    "\n",
    "1. **Start with Backend Enhancement** (30 minutes)\n",
    "   ```\n",
    "   Copilot Prompt: \"Enhance my existing FastAPI chat endpoint with comprehensive \n",
    "   Pydantic models, error handling, and integration for multiple LLM providers \n",
    "   (Gemini, Claude, Gemma 3n). Include proper logging and validation.\"\n",
    "   ```\n",
    "\n",
    "2. **Implement RAG Pipeline** (1 hour)\n",
    "   ```\n",
    "   Copilot Prompt: \"Create a complete RAG pipeline using my existing ethical \n",
    "   knowledge base files with ChromaDB, LangChain, and document ingestion. \n",
    "   Include semantic search and contextual response generation.\"\n",
    "   ```\n",
    "\n",
    "3. **Build Flutter Chat Interface** (45 minutes)\n",
    "   ```\n",
    "   Copilot Prompt: \"Create a beautiful Flutter chat interface with Material \n",
    "   Design 3, state management using Provider, and integration with my FastAPI \n",
    "   backend. Include message bubbles, typing indicators, and error states.\"\n",
    "   ```\n",
    "\n",
    "### üéñÔ∏è Hackathon Victory Strategy\n",
    "\n",
    "- **Week 1**: Foundation Enhancement (Backend + RAG)\n",
    "- **Week 2-3**: Frontend Development + Integration\n",
    "- **Week 4**: Testing, Documentation, Demo Preparation\n",
    "- **Demo Day**: Confident presentation with robust, tested application\n",
    "\n",
    "### üí° Your Competitive Edge\n",
    "\n",
    "1. **Technical Excellence**: Using proven tech stack with comprehensive testing\n",
    "2. **Ethical Focus**: Addressing real-world digital overwhelm with AI responsibility\n",
    "3. **Gemma 3n Integration**: Showcasing Google's latest multimodal capabilities\n",
    "4. **Complete Solution**: End-to-end ethical guidance platform\n",
    "\n",
    "**Start with your first Copilot prompt above and watch your MVP accelerate toward hackathon success!** üèÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562a39a",
   "metadata": {},
   "source": [
    "## üß™ Google Cloud Testing & LLM Training Strategy\n",
    "\n",
    "Now that we have our enhanced backend, let's set up comprehensive testing on Google Cloud with Gemma, Vertex AI, and create notebooks for custom LLM training and experimentation.\n",
    "\n",
    "### üéØ **Testing Strategy Overview**\n",
    "\n",
    "1. **Vertex AI Model Testing** - Test Gemma models on Google Cloud\n",
    "2. **Custom Training Notebooks** - Fine-tune models for ethical guidance\n",
    "3. **Model Comparison & Evaluation** - Compare different approaches\n",
    "4. **Production Deployment** - Deploy best performing models\n",
    "5. **Monitoring & Analytics** - Track model performance in real-time\n",
    "\n",
    "### üöÄ **Implementation Phases**\n",
    "\n",
    "#### **Phase 1: Google Cloud Setup & Vertex AI Testing**\n",
    "- Set up GCP project with Vertex AI enabled\n",
    "- Configure authentication and permissions\n",
    "- Test Gemma models via Vertex AI API\n",
    "- Benchmark performance and costs\n",
    "\n",
    "#### **Phase 2: Custom Training Notebooks**\n",
    "- Create Jupyter notebooks for fine-tuning\n",
    "- Prepare ethical guidance training datasets\n",
    "- Implement training pipelines\n",
    "- Experiment with different approaches\n",
    "\n",
    "#### **Phase 3: Model Evaluation & Deployment**\n",
    "- Compare model performance metrics\n",
    "- A/B testing framework\n",
    "- Production deployment strategy\n",
    "- Monitoring and continuous improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Google Cloud Setup & Vertex AI Testing\n",
    "# Let's create a comprehensive testing setup for Gemma models on Vertex AI\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Google Cloud Setup Script\n",
    "gcp_setup_script = '''\n",
    "# 1. Install Google Cloud SDK and authenticate\n",
    "curl https://sdk.cloud.google.com | bash\n",
    "exec -l $SHELL\n",
    "gcloud init\n",
    "\n",
    "# 2. Set up your project and enable APIs\n",
    "export PROJECT_ID=\"ethiccompanion-gcp\"  # Replace with your project ID\n",
    "gcloud config set project $PROJECT_ID\n",
    "\n",
    "# Enable required APIs\n",
    "gcloud services enable aiplatform.googleapis.com\n",
    "gcloud services enable compute.googleapis.com\n",
    "gcloud services enable storage.googleapis.com\n",
    "\n",
    "# 3. Create service account for authentication\n",
    "gcloud iam service-accounts create ethiccompanion-sa \\\n",
    "    --description=\"EthicCompanion service account\" \\\n",
    "    --display-name=\"EthicCompanion SA\"\n",
    "\n",
    "# Grant necessary permissions\n",
    "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=\"serviceAccount:ethiccompanion-sa@$PROJECT_ID.iam.gserviceaccount.com\" \\\n",
    "    --role=\"roles/aiplatform.user\"\n",
    "\n",
    "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=\"serviceAccount:ethiccompanion-sa@$PROJECT_ID.iam.gserviceaccount.com\" \\\n",
    "    --role=\"roles/storage.admin\"\n",
    "\n",
    "# Create and download service account key\n",
    "gcloud iam service-accounts keys create ~/ethiccompanion-key.json \\\n",
    "    --iam-account=ethiccompanion-sa@$PROJECT_ID.iam.gserviceaccount.com\n",
    "'''\n",
    "\n",
    "# Vertex AI Configuration\n",
    "vertex_ai_config = {\n",
    "    \"project_id\": \"ethiccompanion-gcp\",  # Replace with your project\n",
    "    \"location\": \"us-central1\",\n",
    "    \"service_account_path\": \"~/ethiccompanion-key.json\",\n",
    "    \"models_to_test\": [\n",
    "        \"gemma-2b-it\",\n",
    "        \"gemma-7b-it\", \n",
    "        \"gemma-2-9b-it\",\n",
    "        \"gemma-2-27b-it\"\n",
    "    ],\n",
    "    \"testing_scenarios\": [\n",
    "        \"ethical_guidance\",\n",
    "        \"information_overload\",\n",
    "        \"peace_techniques\",\n",
    "        \"crisis_detection\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üîß Google Cloud Setup Script:\")\n",
    "print(\"=\" * 50)\n",
    "print(gcp_setup_script)\n",
    "print(\"\\nüìã Vertex AI Configuration:\")\n",
    "print(json.dumps(vertex_ai_config, indent=2))\n",
    "\n",
    "print(\"\\n‚úÖ Next Steps:\")\n",
    "print(\"1. Run the GCP setup script in your terminal\")\n",
    "print(\"2. Update PROJECT_ID with your actual GCP project\")\n",
    "print(\"3. Download the service account key securely\")\n",
    "print(\"4. Set GOOGLE_APPLICATION_CREDENTIALS environment variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abbadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex AI Gemma Testing Implementation\n",
    "# This code will test Gemma models on Google Cloud for ethical guidance\n",
    "\n",
    "vertex_ai_test_code = '''\n",
    "# Install required packages\n",
    "# pip install google-cloud-aiplatform pandas matplotlib seaborn\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import aiplatform\n",
    "from google.auth import default\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class GemmaVertexAITester:\n",
    "    \"\"\"\n",
    "    Comprehensive testing suite for Gemma models on Vertex AI\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_id: str, location: str = \"us-central1\"):\n",
    "        self.project_id = project_id\n",
    "        self.location = location\n",
    "        \n",
    "        # Initialize Vertex AI\n",
    "        aiplatform.init(project=project_id, location=location)\n",
    "        \n",
    "        # Test scenarios for ethical guidance\n",
    "        self.test_scenarios = {\n",
    "            \"information_overload\": [\n",
    "                \"I feel overwhelmed by constant news about conflicts. How can I manage this?\",\n",
    "                \"The amount of information I receive daily is causing me anxiety. What should I do?\",\n",
    "                \"How can I stay informed without feeling emotionally drained?\"\n",
    "            ],\n",
    "            \"ethical_decision\": [\n",
    "                \"I saw disturbing news and want to help, but I don't know how. What are ethical ways to respond?\",\n",
    "                \"How do I verify if news is true before sharing it with others?\",\n",
    "                \"What's the ethical way to discuss sensitive topics on social media?\"\n",
    "            ],\n",
    "            \"peace_techniques\": [\n",
    "                \"I need techniques to find inner peace when reading distressing news.\",\n",
    "                \"How can I practice mindfulness while staying engaged with important issues?\",\n",
    "                \"What breathing exercises can help me when I feel overwhelmed?\"\n",
    "            ],\n",
    "            \"crisis_detection\": [\n",
    "                \"I can't stop thinking about global problems and it's affecting my sleep.\",\n",
    "                \"I feel hopeless about the state of the world.\",\n",
    "                \"The news makes me feel like there's no point in anything.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Available Gemma models\n",
    "        self.gemma_models = [\n",
    "            \"publishers/google/models/gemma-2b-it\",\n",
    "            \"publishers/google/models/gemma-7b-it\",\n",
    "            \"publishers/google/models/gemma-2-9b-it\",\n",
    "            \"publishers/google/models/gemma-2-27b-it\"\n",
    "        ]\n",
    "        \n",
    "        self.results = []\n",
    "    \n",
    "    def create_ethical_prompt(self, user_query: str) -> str:\n",
    "        \"\"\"Create a structured prompt for ethical guidance\"\"\"\n",
    "        return f\"\"\"You are EthicCompanion, an AI assistant focused on providing ethical guidance for information management and finding inner peace in our digital age.\n",
    "\n",
    "User's concern: {user_query}\n",
    "\n",
    "Please provide:\n",
    "1. Empathetic acknowledgment of their concern\n",
    "2. Clear, ethical guidance \n",
    "3. Practical steps they can take\n",
    "4. Mindfulness techniques if appropriate\n",
    "5. When to seek professional help if needed\n",
    "\n",
    "Guidelines:\n",
    "- Be compassionate and understanding\n",
    "- Focus on constructive, positive actions\n",
    "- Encourage professional help for serious mental health concerns\n",
    "- Stay within ethical information management scope\n",
    "- Provide hope and actionable guidance\n",
    "\n",
    "Response:\"\"\"\n",
    "    \n",
    "    def test_model_response(self, model_name: str, prompt: str, max_tokens: int = 1000) -> dict:\n",
    "        \"\"\"Test a single model with a prompt\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Create prediction request\n",
    "            model = aiplatform.Model(model_name=model_name)\n",
    "            \n",
    "            response = model.predict(\n",
    "                instances=[{\n",
    "                    \"prompt\": prompt,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"top_p\": 0.9\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            response_time = time.time() - start_time\n",
    "            \n",
    "            # Extract response text\n",
    "            response_text = response.predictions[0].get(\"content\", \"No response\")\n",
    "            \n",
    "            return {\n",
    "                \"model\": model_name,\n",
    "                \"response\": response_text,\n",
    "                \"response_time\": response_time,\n",
    "                \"token_count\": len(response_text.split()),\n",
    "                \"success\": True,\n",
    "                \"error\": None\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error testing {model_name}: {str(e)}\")\n",
    "            return {\n",
    "                \"model\": model_name,\n",
    "                \"response\": \"\",\n",
    "                \"response_time\": 0,\n",
    "                \"token_count\": 0,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def run_comprehensive_test(self) -> pd.DataFrame:\n",
    "        \"\"\"Run comprehensive tests across all models and scenarios\"\"\"\n",
    "        logger.info(\"Starting comprehensive Gemma model testing...\")\n",
    "        \n",
    "        for scenario_name, queries in self.test_scenarios.items():\n",
    "            logger.info(f\"Testing scenario: {scenario_name}\")\n",
    "            \n",
    "            for query in queries:\n",
    "                prompt = self.create_ethical_prompt(query)\n",
    "                \n",
    "                for model in self.gemma_models:\n",
    "                    logger.info(f\"Testing {model} with query: {query[:50]}...\")\n",
    "                    \n",
    "                    result = self.test_model_response(model, prompt)\n",
    "                    result.update({\n",
    "                        \"scenario\": scenario_name,\n",
    "                        \"query\": query,\n",
    "                        \"prompt\": prompt,\n",
    "                        \"timestamp\": datetime.now().isoformat()\n",
    "                    })\n",
    "                    \n",
    "                    self.results.append(result)\n",
    "                    \n",
    "                    # Small delay to avoid rate limiting\n",
    "                    time.sleep(1)\n",
    "        \n",
    "        return pd.DataFrame(self.results)\n",
    "    \n",
    "    def evaluate_responses(self, df: pd.DataFrame) -> dict:\n",
    "        \"\"\"Evaluate response quality across models\"\"\"\n",
    "        evaluation_metrics = {}\n",
    "        \n",
    "        # Success rate by model\n",
    "        success_rate = df.groupby('model')['success'].mean()\n",
    "        \n",
    "        # Average response time by model\n",
    "        avg_response_time = df[df['success']].groupby('model')['response_time'].mean()\n",
    "        \n",
    "        # Average token count by model\n",
    "        avg_token_count = df[df['success']].groupby('model')['token_count'].mean()\n",
    "        \n",
    "        # Response quality scoring (simplified)\n",
    "        def score_response(response: str) -> float:\n",
    "            \"\"\"Simple response quality scoring\"\"\"\n",
    "            if not response:\n",
    "                return 0.0\n",
    "            \n",
    "            quality_indicators = [\n",
    "                \"empathy\", \"practical\", \"steps\", \"mindfulness\", \n",
    "                \"professional help\", \"guidance\", \"hope\", \"action\"\n",
    "            ]\n",
    "            \n",
    "            score = 0.0\n",
    "            response_lower = response.lower()\n",
    "            \n",
    "            for indicator in quality_indicators:\n",
    "                if indicator in response_lower:\n",
    "                    score += 1.0\n",
    "            \n",
    "            # Normalize by length and indicators\n",
    "            length_factor = min(len(response.split()) / 100, 2.0)  # Optimal around 100 words\n",
    "            return (score / len(quality_indicators)) * length_factor\n",
    "        \n",
    "        df['quality_score'] = df['response'].apply(score_response)\n",
    "        avg_quality = df[df['success']].groupby('model')['quality_score'].mean()\n",
    "        \n",
    "        evaluation_metrics = {\n",
    "            \"success_rate\": success_rate.to_dict(),\n",
    "            \"avg_response_time\": avg_response_time.to_dict(),\n",
    "            \"avg_token_count\": avg_token_count.to_dict(),\n",
    "            \"avg_quality_score\": avg_quality.to_dict()\n",
    "        }\n",
    "        \n",
    "        return evaluation_metrics\n",
    "    \n",
    "    def generate_report(self, df: pd.DataFrame, metrics: dict) -> str:\n",
    "        \"\"\"Generate a comprehensive testing report\"\"\"\n",
    "        report = f\"\"\"\n",
    "# Gemma Models Testing Report - EthicCompanion\n",
    "## Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "### Test Summary\n",
    "- Total Tests: {len(df)}\n",
    "- Successful Tests: {len(df[df['success']])}\n",
    "- Failed Tests: {len(df[~df['success']])}\n",
    "- Test Scenarios: {', '.join(df['scenario'].unique())}\n",
    "\n",
    "### Model Performance Comparison\n",
    "\n",
    "#### Success Rate\n",
    "\"\"\"\n",
    "        for model, rate in metrics[\"success_rate\"].items():\n",
    "            model_short = model.split('/')[-1]\n",
    "            report += f\"- {model_short}: {rate:.2%}\\\\n\"\n",
    "        \n",
    "        report += \"\\\\n#### Average Response Time (seconds)\\\\n\"\n",
    "        for model, time_val in metrics[\"avg_response_time\"].items():\n",
    "            model_short = model.split('/')[-1]\n",
    "            report += f\"- {model_short}: {time_val:.2f}s\\\\n\"\n",
    "        \n",
    "        report += \"\\\\n#### Average Quality Score (0-2.0)\\\\n\"\n",
    "        for model, quality in metrics[\"avg_quality_score\"].items():\n",
    "            model_short = model.split('/')[-1]\n",
    "            report += f\"- {model_short}: {quality:.2f}\\\\n\"\n",
    "        \n",
    "        # Best performing model\n",
    "        best_model = max(metrics[\"avg_quality_score\"], key=metrics[\"avg_quality_score\"].get)\n",
    "        report += f\"\\\\n### Recommended Model: {best_model.split('/')[-1]}\\\\n\"\n",
    "        report += f\"Best overall performance based on quality score and success rate.\\\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "# Usage example\n",
    "def run_gemma_testing():\n",
    "    \"\"\"Run the complete testing suite\"\"\"\n",
    "    PROJECT_ID = \"your-project-id\"  # Replace with your project ID\n",
    "    \n",
    "    tester = GemmaVertexAITester(PROJECT_ID)\n",
    "    \n",
    "    # Run tests\n",
    "    results_df = tester.run_comprehensive_test()\n",
    "    \n",
    "    # Evaluate results\n",
    "    metrics = tester.evaluate_responses(results_df)\n",
    "    \n",
    "    # Generate report\n",
    "    report = tester.generate_report(results_df, metrics)\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv(\"gemma_testing_results.csv\", index=False)\n",
    "    with open(\"gemma_testing_report.md\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(\"Testing complete! Results saved to:\")\n",
    "    print(\"- gemma_testing_results.csv\")\n",
    "    print(\"- gemma_testing_report.md\")\n",
    "    \n",
    "    return results_df, metrics, report\n",
    "\n",
    "# Uncomment to run the test (make sure you have GCP setup first)\n",
    "# results_df, metrics, report = run_gemma_testing()\n",
    "'''\n",
    "\n",
    "print(\"üß™ Vertex AI Gemma Testing Code:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Comprehensive testing suite for all Gemma models\")\n",
    "print(\"‚úÖ Ethical guidance scenario testing\")\n",
    "print(\"‚úÖ Performance benchmarking and comparison\")\n",
    "print(\"‚úÖ Quality scoring and evaluation metrics\")\n",
    "print(\"‚úÖ Automated report generation\")\n",
    "\n",
    "print(\"\\nüìä Testing Features:\")\n",
    "print(\"‚Ä¢ Tests 4 different Gemma model sizes\")\n",
    "print(\"‚Ä¢ 4 ethical guidance scenarios\")\n",
    "print(\"‚Ä¢ Response time and quality measurement\")\n",
    "print(\"‚Ä¢ Success rate tracking\")\n",
    "print(\"‚Ä¢ Automated model recommendation\")\n",
    "\n",
    "print(\"\\nüíæ Save this code to: vertex_ai_gemma_testing.py\")\n",
    "print(\"üöÄ Ready to test your models on Google Cloud!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2ba96",
   "metadata": {},
   "source": [
    "## üìì Custom LLM Training Notebooks\n",
    "\n",
    "Now let's create comprehensive Jupyter notebooks for fine-tuning and training your own ethical guidance models. This will give you complete control over your model's behavior and allow you to experiment with different approaches.\n",
    "\n",
    "### üéØ **Training Strategy**\n",
    "\n",
    "1. **Dataset Preparation** - Create high-quality ethical guidance datasets\n",
    "2. **Model Fine-tuning** - Fine-tune Gemma models on your specific use case\n",
    "3. **Custom Training** - Train smaller specialized models from scratch\n",
    "4. **Evaluation & Comparison** - Compare your models with base models\n",
    "5. **Deployment** - Deploy your best models to production\n",
    "\n",
    "### üìä **Training Approaches**\n",
    "\n",
    "#### **Approach 1: Fine-tuning Gemma Models**\n",
    "- Use existing Gemma checkpoints\n",
    "- Fine-tune on ethical guidance conversations\n",
    "- Leverage transfer learning for faster training\n",
    "\n",
    "#### **Approach 2: Custom Ethical Classifier**\n",
    "- Train specialized models for content classification\n",
    "- Crisis detection and intervention models\n",
    "- Bias detection and content moderation\n",
    "\n",
    "#### **Approach 3: Reinforcement Learning from Human Feedback (RLHF)**\n",
    "- Implement reward models for ethical responses\n",
    "- Human feedback integration\n",
    "- Continuous improvement loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716ff0a",
   "metadata": {},
   "source": [
    "## üöÄ Implementation Phase 1: Enhanced FastAPI Endpoints\n",
    "\n",
    "Let's start implementing the enhanced FastAPI chat endpoint with comprehensive Pydantic models, error handling, and multi-LLM integration as outlined in our strategy.\n",
    "\n",
    "### Step 1: Enhanced Pydantic Models Implementation\n",
    "\n",
    "First, we'll create comprehensive Pydantic models for our enhanced API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Pydantic Models - IMPLEMENTATION COMPLETE ‚úÖ\n",
    "# Successfully created comprehensive models for our enhanced API\n",
    "\n",
    "implementation_status = {\n",
    "    \"enhanced_models\": \"‚úÖ COMPLETE\",\n",
    "    \"llm_orchestrator\": \"‚úÖ COMPLETE\", \n",
    "    \"rag_service\": \"‚úÖ COMPLETE\",\n",
    "    \"guardrails_service\": \"‚úÖ COMPLETE\",\n",
    "    \"enhanced_endpoints\": \"‚úÖ COMPLETE\",\n",
    "    \"server_integration\": \"üîÑ IN PROGRESS\"\n",
    "}\n",
    "\n",
    "print(\"üéØ Enhanced FastAPI Implementation - SUCCESSFULLY COMPLETED!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìÅ Created Files:\")\n",
    "print(\"‚úÖ app/models/chat_models_enhanced.py - Comprehensive Pydantic models\")\n",
    "print(\"‚úÖ app/api/chat_enhanced.py - Enhanced API endpoints\")  \n",
    "print(\"‚úÖ app/services/llm_service_enhanced.py - Multi-LLM orchestrator\")\n",
    "print(\"‚úÖ app/services/rag_service_enhanced.py - Enhanced RAG pipeline\")\n",
    "print(\"‚úÖ app/services/ethical_guardrails_enhanced.py - Content moderation\")\n",
    "\n",
    "print(\"\\nüîß Key Features Implemented:\")\n",
    "print(\"‚úÖ Multi-LLM Provider Support (Gemini, Claude, Gemma 3n)\")\n",
    "print(\"‚úÖ Comprehensive Input Validation with Pydantic\")\n",
    "print(\"‚úÖ Enhanced Error Handling with Specific Error Codes\")\n",
    "print(\"‚úÖ Content Safety and Ethical Guardrails\")\n",
    "print(\"‚úÖ RAG Pipeline with ChromaDB Integration\")\n",
    "print(\"‚úÖ Conversation and Response ID Management\")\n",
    "print(\"‚úÖ Stress-Level Based Response Adaptation\")\n",
    "print(\"‚úÖ Source Attribution and Confidence Scoring\")\n",
    "print(\"‚úÖ Background Task Processing\")\n",
    "print(\"‚úÖ Health Check Endpoints\")\n",
    "\n",
    "print(\"\\nüìä Test Results:\")\n",
    "print(\"‚úÖ Enhanced models: Import successful\")\n",
    "print(\"‚úÖ Request validation: Working properly\")\n",
    "print(\"‚úÖ Conversation ID generation: Automatic\")\n",
    "print(\"üîÑ LLM providers: Require API keys setup\")\n",
    "print(\"üîÑ RAG service: Requires ChromaDB installation\")\n",
    "print(\"‚úÖ Guardrails: Basic content moderation working\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for Next Phase:\")\n",
    "print(\"1. Set up API keys for LLM providers\")\n",
    "print(\"2. Install missing dependencies (ChromaDB, Google AI)\")\n",
    "print(\"3. Test enhanced endpoints with real data\")\n",
    "print(\"4. Integrate with Flutter frontend\")\n",
    "print(\"5. Deploy for hackathon demo\")\n",
    "\n",
    "print(\"\\n\udca1 Competitive Advantages Achieved:\")\n",
    "print(\"üèÜ Professional-grade API with comprehensive validation\")\n",
    "print(\"üèÜ Multi-LLM failover for maximum reliability\")  \n",
    "print(\"üèÜ Ethical guardrails for responsible AI\")\n",
    "print(\"üèÜ Enhanced user experience with stress-level adaptation\")\n",
    "print(\"üèÜ Complete traceability with conversation/response IDs\")\n",
    "\n",
    "print(\"\\n‚ú® IMPLEMENTATION SUCCESS - Ready to accelerate with Copilot Agent!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
