# EthicCompanion: Gemma 3n Integration Guide for Hackathon

## üéØ Overview
This guide demonstrates how EthicCompanion leverages **Gemma 3n** for the Google Gemma 3n Impact Challenge, implementing multimodal ethical AI for information overload management.

## üöÄ Tech Stack Implementation

### Frontend
- **Flutter** - Cross-platform UI for web/mobile access

### Backend  
- **FastAPI** - High-performance Python API framework
- **Gemma 3n Integration** - Multimodal AI processing (text, image, audio)

### Databases
- **Firebase Firestore** - User data and conversation history
- **Vertex AI Vector Search** - Semantic search for ethical knowledge base
- **ChromaDB** - Local vector storage for RAG pipeline

### AI & Machine Learning
#### Core Models
- **Gemma 3n E2B** (2B effective params) - Fast ethical classifications
- **Gemma 3n E4B** (4B effective params) - Complex ethical reasoning  
- **Google Gemini** - Advanced reasoning backup
- **Claude (Anthropic)** - Ethical guidance diversity

#### RAG Implementation
- **LangChain** - Orchestration framework for RAG pipeline
- **Vertex AI Embeddings** - High-quality semantic embeddings
- **HuggingFace Transformers** - NLP model management
- **Sentence Transformers** - Fallback embedding generation

#### Ethical AI & Guardrails
- **NeMo Guardrails** - Behavior rules and safety limits
- **Google Perspective API** - Content moderation
- **Custom Ethical Classifiers** - Crisis detection and bias identification
- **Human-in-the-Loop** - Feedback and continuous improvement

#### Cloud Infrastructure
- **Google Cloud Platform** - Primary cloud provider
- **Vertex AI** - Model training and deployment
- **Firebase** - Authentication and hosting

## üîß Quick Start Implementation

### 1. Install Dependencies
```bash
cd ethiccompanion-mvp/backend
pip install -r requirements.txt
```

### 2. Environment Setup
Create `.env` file:
```env
# Google Cloud
GOOGLE_CLOUD_PROJECT=your_project_id
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json

# API Keys
GEMINI_API_KEY=your_gemini_key
ANTHROPIC_API_KEY=your_claude_key
PERSPECTIVE_API_KEY=your_perspective_key

# Hugging Face (for Gemma 3n access)
HUGGINGFACE_TOKEN=your_hf_token
```

### 3. Initialize Services
```python
from app.services.llm_service_enhanced import LLMOrchestrator, Gemma3nManager
from app.services.rag_service_enhanced import EnhancedRAGService
from app.services.ethical_guardrails_enhanced import EthicalGuardrails

# Initialize Gemma 3n
gemma_manager = Gemma3nManager()
await gemma_manager.load_model("e2b")  # Fast model
await gemma_manager.load_model("e4b")  # Advanced model

# Initialize LLM orchestrator
llm_orchestrator = LLMOrchestrator()

# Initialize RAG service
rag_service = EnhancedRAGService()
await rag_service.initialize()

# Initialize ethical guardrails
guardrails = EthicalGuardrails()
await guardrails.initialize()
```

### 4. Process User Query
```python
async def process_ethical_query(user_input: str, images: list = None):
    # 1. Content moderation
    moderation_result = await guardrails.moderate_input(user_input)
    
    if moderation_result.requires_intervention:
        return await handle_crisis_intervention(moderation_result)
    
    # 2. RAG retrieval
    rag_result = await rag_service.generate_rag_response(
        query=user_input,
        llm_orchestrator=llm_orchestrator
    )
    
    # 3. Gemma 3n processing (multimodal if images provided)
    if images:
        response = await gemma_manager.generate_response(
            prompt=rag_result.generated_response,
            model_size="e4b",  # Use advanced model for multimodal
            images=images
        )
    else:
        response = await gemma_manager.generate_response(
            prompt=rag_result.generated_response,
            model_size="e2b"  # Use fast model for text-only
        )
    
    # 4. Output moderation
    output_check = await guardrails.moderate_output(response.content)
    
    if output_check.moderation_result == ModerationResult.APPROVED:
        return response
    else:
        return generate_safe_fallback_response()
```

## üé≠ Gemma 3n Hackathon Features

### 1. **Multimodal Ethical Analysis**
```python
# Process news image with ethical context
async def analyze_news_image(image, user_query):
    prompt = f"""
    Analyze this image in the context of: {user_query}
    
    Consider:
    1. Emotional impact of visual content
    2. Potential for information overwhelm
    3. Constructive ways to process this information
    4. Mindfulness techniques for emotional regulation
    
    Provide ethical guidance for healthy information consumption.
    """
    
    return await gemma_manager.generate_response(
        prompt=prompt,
        model_size="e4b",
        images=[image]
    )
```

### 2. **Efficient Content Classification**
```python
# Fast ethical scope detection with Gemma 3n E2B
async def classify_content_scope(text):
    prompt = f"Classify if this requires ethical guidance: {text}"
    
    result = await gemma_manager.generate_response(
        prompt=prompt,
        model_size="e2b"  # Fast 2B model for classification
    )
    
    return "ethical_guidance" in result.content.lower()
```

### 3. **Crisis Detection Pipeline**
```python
# Advanced crisis detection with Gemma 3n E4B
async def detect_crisis_indicators(user_message):
    prompt = f"""
    Analyze this message for crisis indicators:
    "{user_message}"
    
    Look for:
    - Expressions of hopelessness
    - Self-harm ideation
    - Extreme overwhelm
    - Isolation indicators
    
    Respond with: CRISIS_DETECTED or NORMAL_CONCERN
    """
    
    result = await gemma_manager.generate_response(
        prompt=prompt,
        model_size="e4b"  # Use advanced model for nuanced detection
    )
    
    return "CRISIS_DETECTED" in result.content
```

### 4. **Information Overload Management**
```python
# Personalized digital wellness guidance
async def generate_wellness_plan(user_context, stress_level):
    prompt = f"""
    Create a personalized digital wellness plan for:
    Context: {user_context}
    Stress Level: {stress_level}
    
    Include:
    1. Specific time limits for news consumption
    2. Mindfulness techniques for emotional regulation
    3. Constructive action suggestions
    4. Inner peace cultivation methods
    
    Make it practical and immediately actionable.
    """
    
    return await gemma_manager.generate_response(
        prompt=prompt,
        model_size="e4b",
        max_tokens=1024
    )
```

## üìä Performance Optimization

### Model Selection Strategy
```python
# Intelligent model routing based on use case
def select_optimal_model(use_case, has_multimodal_input):
    if has_multimodal_input:
        return "e4b"  # Always use advanced model for multimodal
    
    model_routing = {
        "ethical_classification": "e2b",  # Fast classification
        "crisis_detection": "e4b",       # Nuanced analysis needed
        "general_guidance": "e2b",       # Efficient guidance
        "complex_reasoning": "e4b"       # Deep ethical analysis
    }
    
    return model_routing.get(use_case, "e2b")
```

### Efficient Resource Management
```python
# Load models on-demand to optimize memory
class OptimizedGemmaManager:
    async def process_request(self, request):
        required_model = self.select_optimal_model(request.use_case)
        
        # Load only required model
        if required_model not in self.loaded_models:
            await self.load_model(required_model)
        
        # Unload unused models if memory is constrained
        await self.optimize_memory_usage()
        
        return await self.generate_response(request, required_model)
```

## üéØ Hackathon Impact Demonstration

### 1. **Information Overload Relief**
- **Before**: User overwhelmed by constant war news
- **After**: Personalized consumption limits + mindfulness techniques
- **Gemma 3n Role**: Processes emotional context in text/images for tailored guidance

### 2. **Crisis Intervention**
- **Before**: User expressing hopelessness about world events  
- **After**: Immediate crisis resources + professional help connections
- **Gemma 3n Role**: Sophisticated crisis pattern detection in user messages

### 3. **Constructive Action Transformation**
- **Before**: User feeling helpless about global issues
- **After**: Specific, actionable steps for positive impact
- **Gemma 3n Role**: Analyzes user context to suggest personalized ethical actions

### 4. **Digital Wellness Enhancement**
- **Before**: Compulsive doomscrolling and information anxiety
- **After**: Healthy information diet + emotional regulation tools
- **Gemma 3n Role**: Multimodal analysis of user's digital consumption patterns

## üèÜ Competitive Advantages

1. **Gemma 3n Efficiency**: 2B/4B effective parameters enable real-time processing
2. **Multimodal Understanding**: Process text, images, and audio for comprehensive support
3. **Ethical Specialization**: Custom-trained for ethical guidance scenarios
4. **Crisis Prevention**: Advanced detection prevents mental health crises
5. **Global Accessibility**: 140+ language support via Gemma 3n training data

## üìà Metrics for Success

### Technical Metrics
- **Response Time**: <2 seconds for E2B, <5 seconds for E4B
- **Accuracy**: >90% for ethical scope classification
- **Crisis Detection**: >95% sensitivity for intervention needs
- **User Satisfaction**: >4.5/5 rating for guidance quality

### Impact Metrics  
- **Stress Reduction**: Measured via pre/post anxiety questionnaires
- **Constructive Actions**: Track user-reported positive actions taken
- **Digital Wellness**: Monitor healthy information consumption patterns
- **Crisis Prevention**: Count successful interventions and resource connections

This implementation showcases how Gemma 3n's efficiency and multimodal capabilities make EthicCompanion a powerful tool for ethical information processing and mental wellness support.
